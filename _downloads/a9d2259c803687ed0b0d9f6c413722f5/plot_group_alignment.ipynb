{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Template-based prediction.\n\nIn this tutorial, we show how to improve inter-subject similarity using a template\ncomputed across multiple source subjects. For this purpose, we leverage GroupAlignment\nto create a template, using Procrustes alignment. Leveraging the learned template,\nwe align the target subject using shared information.\nWe then compare the voxelwise similarity between the\ntarget subject and the template to the similarity between the target subject and\nthe anatomical Euclidean average of the source subjects.\n\nWe mostly rely on Python common packages and on nilearn to handle\nfunctional data in a clean fashion.\n\n\nTo run this example, you must launch IPython via ``ipython\n--matplotlib`` in a terminal, or use ``jupyter-notebook``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve the data\nIn this example we use the IBC dataset, which includes a large number of\ndifferent contrasts maps for 12 subjects.\nWe download the images for subjects sub-01, sub-02, sub-04, sub-05, sub-06\nand sub-07 (or retrieve them if they were already downloaded).\nimgs is the list of paths to available statistical images for each subjects.\ndf is a dataframe with metadata about each of them.\nmask is a binary image used to extract grey matter regions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign.fetch_example_data import fetch_ibc_subjects_contrasts\n\nsubjects = [\"sub-01\", \"sub-02\", \"sub-04\", \"sub-05\", \"sub-06\", \"sub-07\"]\nimgs, df, mask_img = fetch_ibc_subjects_contrasts(subjects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a masker\nWe define a nilearn masker that will be used to handle relevant data.\nFor more information, consult Nilearn's documentation on\n:external+nilearn`masker objects <masker_objects>`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.maskers import NiftiMasker\n\nmasker = NiftiMasker(mask_img=mask_img).fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the data\nFor each subject, we will use two series of contrasts acquired during\ntwo independent sessions with a different phase encoding:\nAntero-posterior(AP) or Postero-anterior(PA).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To infer a template for subjects sub-01 to sub-06 for both AP and PA data,\n# we make a list of 4D niimgs from our list of list of files containing 3D images\n\nfrom nilearn.image import concat_imgs\n\ntemplate_train = []\nfor i in range(5):\n    template_train.append(concat_imgs(imgs[i]))\n\n# sub-07 (that is 5th in the list) will be our left-out subject.\n# We make a single 4D Niimg from our list of 3D filenames.\n\nleft_out_subject = concat_imgs(imgs[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute a baseline (average of subjects)\nWe create an image with as many contrasts as any subject representing for\neach contrast the average of all train subjects maps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nmasked_imgs = [masker.transform(img) for img in template_train]\neuclidean_avg = np.mean(masked_imgs, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a template from the training subjects.\nWe define an estimator using :class:`~fmralign.alignment.group_alignment.GroupAlignment`:\n  * We align the whole brain through multiple local alignments.\n  * These alignments are calculated on a parcellation of the brain in 150 pieces,\n    this parcellation creates group of functionally similar voxels.\n  * The template is created iteratively, aligning all subjects data into a\n    common space, from which the template is inferred and aligning again to this\n    new template space.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign import GroupAlignment\nfrom fmralign.embeddings.parcellation import get_labels\n\n# Use only the first image to speed up the computation of the labels\nlabels = get_labels(imgs[0], n_pieces=150, masker=masker)\n\n# We create a dictionary with the subject names as keys and the subjects data as values\ndict_alignment = dict(zip(subjects, masked_imgs))\n\n# We use Procrustes/scaled orthogonal alignment method\ntemplate_estim = GroupAlignment(method=\"procrustes\", labels=labels)\ntemplate_estim.fit(X=dict_alignment, y=\"template\")\nprocrustes_template = template_estim.template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict new data for left-out subject\nWe predict the contrasts of the left-out subject using the template we just\ncreated. This method takes the left-out subject as input, computes a pairwise\nalignment with the template and returns the aligned data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign import PairwiseAlignment\n\nleft_out_data = masker.transform(left_out_subject)\npairwise_estim = PairwiseAlignment(method=\"procrustes\", labels=labels).fit(\n    left_out_data, procrustes_template\n)\n\npredictions_from_template = pairwise_estim.transform(left_out_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Score the baseline and the prediction\nWe use a utility scoring function to measure the voxelwise correlation\nbetween the images. That is, for each voxel, we measure the correlation between\nits profile of activation without and with alignment, to see if template-based\nalignment was able to improve inter-subject similarity.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign.metrics import score_voxelwise\n\naverage_score = score_voxelwise(left_out_data, euclidean_avg, loss=\"corr\")\ntemplate_score = score_voxelwise(\n    predictions_from_template, procrustes_template, loss=\"corr\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the measures\nFinally we plot both scores\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import plotting\n\naverage_score_img = masker.inverse_transform(average_score)\ntemplate_score_img = masker.inverse_transform(template_score)\nbaseline_display = plotting.plot_stat_map(\n    average_score_img, display_mode=\"z\", vmax=1, cut_coords=[-15, -5]\n)\nbaseline_display.title(\"Left-out subject correlation with group average\")\ndisplay = plotting.plot_stat_map(\n    template_score_img, display_mode=\"z\", cut_coords=[-15, -5], vmax=1\n)\ndisplay.title(\"Aligned subject correlation with Procrustes template\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that creating a template and aligning a new subject to it yields\nbetter inter-subject similarity than regular euclidean averaging.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Pairwise surface alignment.\n\nIn this tutorial, we show how to align surface data from two subjects using\na pairwise alignment method. We project the data on the `fsaverage5` surface\nand learn a piecewise mapping from one subject to the other using ward clustering.\n\n\nWe mostly rely on python common packages and on nilearn to handle functional\ndata in a clean fashion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve the data\nIn this example we use the IBC dataset, which include a large number of\ndifferent contrasts maps for 12 subjects. We download the images for\nsubjects sub-01 and sub-04 (or retrieve them if they were already downloaded)\nFiles is the list of paths for each subjects.\ndf is a dataframe with metadata about each of them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign.fetch_example_data import fetch_ibc_subjects_contrasts\n\nfiles, df, _ = fetch_ibc_subjects_contrasts([\"sub-01\", \"sub-04\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project the data on the fsaverage5 surface\nWe project the data on the fsaverage5 surface, using the fsaverage5\nsurface template.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import load_fsaverage, load_fsaverage_data\nfrom nilearn.surface import SurfaceImage\n\nfsaverage_meshes = load_fsaverage()\n\n\ndef project_to_surface(img):\n    \"\"\"Util function for loading and projecting volumetric images.\"\"\"\n    surface_image = SurfaceImage.from_volume(\n        mesh=fsaverage_meshes[\"pial\"],\n        volume_img=img,\n    )\n    return surface_image\n\n\nfrom nilearn.image import concat_imgs\n\nsource_train = concat_imgs(\n    df[df.subject == \"sub-01\"][df.acquisition == \"ap\"].path.values\n)\ntarget_train = concat_imgs(\n    df[df.subject == \"sub-04\"][df.acquisition == \"ap\"].path.values\n)\n\nsurf_source_train = project_to_surface(source_train)\nsurf_target_train = project_to_surface(target_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fitting the alignment operator\nWe use the `PairwiseAlignment` class to learn the alignment operator from\none subject to the other. We select the `scaled_orthogonal` method to compute\na rigid piecewise alignment mapping and the `ward` clustering method to\nparcellate the cortical surface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign.pairwise_alignment import PairwiseAlignment\n\nalignment_estimator = PairwiseAlignment(\n    alignment_method=\"scaled_orthogonal\",\n    n_pieces=100,\n    clustering=\"ward\",\n)\n# Learn alignment operator from subject 1 to subject 2 on training data\nalignment_estimator.fit(surf_source_train, surf_target_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the computed parcellation\nWe can retrieve the computed parcellation and plot it on the surface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import plotting\n\n_, clustering_img = alignment_estimator.get_parcellation()\n\n\nplotting.plot_surf_roi(\n    surf_mesh=fsaverage_meshes[\"pial\"],\n    roi_map=clustering_img,\n    hemi=\"left\",\n    view=\"lateral\",\n    title=\"Ward parcellation on the left hemisphere\",\n)\nplotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Projecting the left-out data\nLet's now align a left-out audio contrast from sub-01 to sub-04. We project\nthe data on the surface and apply the learned alignment operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "surf_audio_source = project_to_surface(\n    df[\n        (df.subject == \"sub-01\")\n        & (df.condition == \"audio_sentence\")\n        & (df.acquisition == \"pa\")\n    ].path.values\n)\n\nsurf_audio_target = project_to_surface(\n    df[\n        (df.subject == \"sub-04\")\n        & (df.condition == \"audio_sentence\")\n        & (df.acquisition == \"pa\")\n    ].path.values\n)\n\nsurf_aligned = alignment_estimator.transform(surf_audio_source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the alignment in action\nWe interpolate between the source and aligned images to visualize the\nalignment process. Notice how the individual idiocyncracies of the source\nsubject are progressively removed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\n\nfsaverage_sulcal = load_fsaverage_data(\n    mesh=\"fsaverage5\",\n    data_type=\"sulcal\",\n    mesh_type=\"inflated\",\n)\n\nplotting_params = {\n    \"bg_map\": fsaverage_sulcal,\n    \"hemi\": \"left\",\n    \"view\": \"lateral\",\n    \"colorbar\": True,\n    \"alpha\": 0.5,\n    \"bg_on_data\": True,\n    \"vmax\": 3,\n    \"vmin\": -3,\n    \"cmap\": \"coolwarm\",\n}\n\n\ndef interpolate_surf_image(surf_img1, surf_img2, alpha=0.5):\n    \"\"\"Interpolate two surface images.\"\"\"\n    # Create a new surface image with the same mesh as the input\n    surf_img_interpolated = deepcopy(surf_img1)\n    # Interpolate the data\n    for hemi in [\"left\", \"right\"]:\n        surf_img_interpolated.data.parts[hemi] = (\n            surf_img1.data.parts[hemi] * (1 - alpha)\n            + surf_img2.data.parts[hemi] * alpha\n        )\n    return surf_img_interpolated\n\n\n# Create figure\nfig = plt.figure(figsize=(10, 8))\n\n\n# Define a function to update the figure for each frame\ndef update(frame):\n    plt.clf()\n\n    if frame <= 10:\n        # Interpolation frames (0-10)\n        alpha = frame / 10\n        surf_interpolated = interpolate_surf_image(\n            surf_audio_source, surf_aligned, alpha=alpha\n        )\n        plotting.plot_surf_stat_map(\n            surf_mesh=fsaverage_meshes[\"pial\"],\n            stat_map=surf_interpolated,\n            figure=fig,\n            **plotting_params,\n        )\n        plt.suptitle(\n            f\"Interpolated audio sentence alpha={alpha:.1f}\", fontsize=16\n        )\n    else:\n        # Target image (frame 10)\n        plotting.plot_surf_stat_map(\n            surf_mesh=fsaverage_meshes[\"pial\"],\n            stat_map=surf_audio_target,\n            figure=fig,\n            **plotting_params,\n        )\n        plt.suptitle(\"Target image\", fontsize=16)\n\n    return [fig]\n\n\n# Create the animation\nanim = FuncAnimation(fig, update, frames=range(12), interval=300, blit=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}